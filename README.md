# Sexism Detector - Progetto di AI UNIBO
The accessibility of artificial intelligence (AI) models to the general public has raised concerns about their behavior and potential biases. In the field of Natural Language Processing (NLP), there is ongoing debate surrounding the fairness of language models (LMs) and their ability to produce or perpetuate discriminatory biases. This paper focuses on addressing gender bias in NLP, specifically examining gender-biased expressions generated by Language Models (LMs) that reflect societal beliefs or stereotypes about women. The study utilizes the BERT model and employs the mask language model (MLM) technique. Three tests are conducted using template-based sentences to observe instances of inequality and sexist content when the subject transitions from male-associated to female-associated gender. Qualitative evaluations are performed using various tools and techniques based on the test type. The results highlight the presence of gender bias in LM outputs and emphasize the need for strategies to minimize or eliminate biases in AI systems.